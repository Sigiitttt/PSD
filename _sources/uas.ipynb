{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNxHGeDi/RezOtx+ZehieFw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Business Understanding**\n","\n","##### **1. Latar Belakang Masalah**\n","\n","Perkembangan teknologi di bidang biomedis dan analitik data memungkinkan pemanfaatan sinyal fisiologis manusia sebagai sumber informasi untuk berbagai kebutuhan, seperti identifikasi individu, sistem keamanan, dan pemantauan kesehatan. Salah satu sinyal fisiologis yang banyak diteliti adalah surface Electromyography (sEMG), yaitu sinyal listrik yang dihasilkan oleh aktivitas otot dan direkam melalui permukaan kulit.\n","\n","Setiap individu memiliki karakteristik otot dan pola aktivitas listrik yang berbeda, sehingga sinyal sEMG berpotensi digunakan sebagai ciri biometrik. Namun, data sEMG bersifat kompleks, berdimensi tinggi, dan dipengaruhi oleh berbagai faktor, sehingga diperlukan pendekatan Data Science dan Machine Learning untuk mengekstraksi pola yang bermakna dari data tersebut.\n","\n","Dataset SemgHandSubjectCh2 menyediakan data sEMG berbasis spektrum daya dari beberapa subjek yang melakukan aktivitas genggaman tangan. Dataset ini dapat dimanfaatkan untuk membangun model klasifikasi yang mampu mengidentifikasi subjek berdasarkan karakteristik sinyal sEMG.\n","\n","\n","\n","##### **2. Permasalahan Bisnis (Business Problem)**\n","\n","Dalam konteks dunia nyata, terdapat kebutuhan akan sistem yang mampu:\n","\n","* Mengidentifikasi individu secara non-invasif\n","* Memanfaatkan sinyal fisiologis alami tanpa memerlukan input eksplisit dari pengguna\n","* Bekerja dengan data sinyal biologis yang kompleks\n","\n","Namun, tanpa analisis data yang tepat, sinyal sEMG sulit digunakan secara langsung karena:\n","\n","* Memiliki variabilitas tinggi\n","* Bersifat non-linear\n","* Mengandung noise\n","\n","Oleh karena itu, diperlukan sistem berbasis Data Science yang mampu mengklasifikasikan identitas subjek secara akurat berdasarkan sinyal sEMG.\n","\n","\n","\n","##### **3. Tujuan Proyek (Business Objectives)**\n","\n","Tujuan utama dari proyek ini adalah:\n","\n","> Membangun dan mengevaluasi model klasifikasi berbasis Data Science yang mampu mengidentifikasi subjek berdasarkan sinyal sEMG Channel 2 dengan tingkat akurasi yang baik.\n","\n","Tujuan khusus meliputi:\n","\n","1. Memahami karakteristik data sEMG berbasis spektrum daya\n","2. Melakukan pra-pemrosesan data agar siap digunakan untuk pemodelan\n","3. Membangun model klasifikasi multi-kelas (5 kelas subjek)\n","4. Mengevaluasi performa model menggunakan metrik evaluasi yang sesuai\n","5. Menentukan model terbaik berdasarkan hasil evaluasi\n","\n","\n","\n","##### **4. Manfaat Bisnis (Business Value)**\n","\n","Hasil dari proyek ini diharapkan memberikan manfaat sebagai berikut:\n","\n","**Manfaat Praktis**\n","\n","* Menjadi dasar pengembangan sistem identifikasi biometrik berbasis sEMG\n","* Mendukung penelitian di bidang biomedis, wearable devices, dan humanâ€“computer interaction\n","* Memberikan gambaran penerapan Data Science pada data sinyal fisiologis\n","\n","**Manfaat Akademis**\n","\n","* Menjadi studi kasus penerapan metode klasifikasi machine learning\n","* Menambah pemahaman tentang pengolahan data time-series dan signal-based data\n","* Melatih kemampuan analisis data kompleks dalam konteks dunia nyata\n","\n","\n","\n","##### **5. Ruang Lingkup Proyek (Scope)**\n","\n","Agar proyek tetap terfokus, ruang lingkup proyek dibatasi sebagai berikut:\n","\n","* Dataset yang digunakan: SemgHandSubjectCh2\n","* Data yang dianalisis: hasil ekstraksi spektrum daya (bukan sinyal mentah)\n","* Channel yang digunakan: Channel 2\n","* Jumlah kelas: 5 subjek\n","* Metode yang digunakan: klasifikasi berbasis Machine Learning / Deep Learning\n","* Proyek ini tidak mencakup implementasi perangkat keras atau sistem real-time\n","\n","\n","\n","##### **6. Kriteria Keberhasilan (Success Criteria)**\n","\n","Proyek dikatakan berhasil apabila:\n","\n","1. Model mampu melakukan klasifikasi subjek dengan performa yang baik\n","2. Nilai akurasi dan metrik evaluasi lainnya menunjukkan hasil yang konsisten\n","3. Model dapat menggeneralisasi data uji dengan baik (tidak overfitting)\n","4. Hasil analisis dapat dijelaskan secara logis dan ilmiah\n","\n","##### **7. Ringkasan Business Understanding**\n","\n","Secara keseluruhan, proyek ini bertujuan untuk memanfaatkan data sEMG sebagai sumber informasi biometrik melalui pendekatan Data Science. Dengan membangun model klasifikasi yang tepat, diharapkan sistem dapat mengenali identitas subjek berdasarkan pola aktivitas otot tangan secara efektif.\n","\n","\n"],"metadata":{"id":"PvNv65ISAqj8"}},{"cell_type":"markdown","source":["# **Data Understanding**\n","\n","##### **1. Deskripsi Dataset**\n","\n","Dataset yang digunakan dalam proyek ini adalah SemgHandSubjectCh2, yang merupakan bagian dari dataset SEMG for Basic Hand Movements yang tersedia pada UCI Machine Learning Repository. Dataset ini berisi data surface Electromyography (sEMG) yang direkam dari aktivitas otot tangan manusia menggunakan sistem EMG dua kanal, di mana pada proyek ini hanya digunakan Channel 2.\n","\n","Data yang digunakan bukan berupa sinyal mentah, melainkan hasil ekstraksi spektrum daya (power spectrum) dari sinyal sEMG, sehingga data berada pada domain frekuensi.\n","\n","**sumber dataset**   https://www.timeseriesclassification.com/description.php?Dataset=SemgHandSubjectCh2\n","\n","\n","\n","##### **2. Struktur dan Karakteristik Data**\n","\n","Dataset tidak berbentuk tabel seperti data tabular (CSV dengan kolom bernama), melainkan berbentuk data sinyal numerik.\n","\n","Struktur variabelnya adalah:\n","\n","| Karakteristik         | Nilai                        |\n","|-----------------------|------------------------------|\n","| Jumlah data latih     | 450 sampel                   |\n","| Jumlah data uji       | 450 sampel                   |\n","| Panjang setiap sampel | 1500 titik                   |\n","| Jumlah dimensi        | 1                            |\n","| Jumlah kelas          | 5                            |\n","| Jenis data            | Spectrogram / Power Spectrum |\n","| Channel               | Channel 2                    |\n","\n","Setiap sampel data direpresentasikan sebagai vektor satu dimensi dengan panjang 1500 yang menggambarkan distribusi energi sinyal sEMG pada domain frekuensi.\n","\n","\n","\n","##### **3. Deskripsi Label / Target**\n","\n","Label pada dataset SemgHandSubjectCh2 merepresentasikan identitas subjek, bukan jenis gerakan tangan. Adapun pembagian kelas adalah sebagai berikut:\n","\n","| Label   | Subjek   |\n","| --------|----------|\n","| Class 1 | Female 1 |\n","| Class 2 | Female 2 |\n","| Class 3 | Female 3 |\n","| Class 4 | Male 1   |\n","| Class 5 | Male 2   |\n","\n","Dengan demikian, permasalahan yang dihadapi dalam proyek ini adalah klasifikasi multi-kelas dengan lima kelas target.\n","\n","\n","\n","##### **4. Distribusi Data**\n","\n","Dataset telah disediakan dalam bentuk data latih dan data uji terpisah, dengan jumlah sampel yang seimbang:\n","\n","* 450 data latih\n","* 450 data uji\n","\n","Distribusi kelas pada dataset bersifat relatif seimbang, sehingga tidak diperlukan teknik penanganan ketidakseimbangan data seperti oversampling atau undersampling pada tahap awal.\n","\n","Selain itu, urutan data tidak memiliki makna tertentu, sehingga setiap sampel dianggap independen satu sama lain.\n","\n","\n","\n","##### **5. Tipe dan Karakteristik Data**\n","\n","Berdasarkan bentuk dan sifatnya, data memiliki karakteristik sebagai berikut:\n","\n","* Numerik kontinu\n","* Berdimensi tinggi (1500 fitur per sampel)\n","* Berbasis sinyal frekuensi\n","* Memiliki potensi korelasi antar fitur\n","\n","Karakteristik ini mengindikasikan perlunya:\n","\n","* Normalisasi atau standarisasi data\n","* Teknik reduksi dimensi (opsional)\n","* Model yang mampu menangani data berdimensi tinggi\n","\n","\n","\n","##### **6. Kualitas Data**\n","\n","Berdasarkan deskripsi dataset:\n","\n","* Data tidak mengandung nilai kosong (*missing values*)\n","* Data telah melalui proses ekstraksi spektrum daya\n","* Noise relatif lebih rendah dibandingkan sinyal mentah\n","\n","Namun demikian, tetap diperlukan:\n","\n","* Pemeriksaan nilai ekstrem (*outliers*)\n","* Analisis statistik dasar untuk memahami rentang nilai data\n","* Visualisasi data untuk memahami pola awal\n","\n","\n","\n","##### **7. Eksplorasi Awal Data (Initial Data Exploration)**\n","\n","Pada tahap awal eksplorasi data, analisis yang dapat dilakukan meliputi:\n","\n","1. Analisis statistik deskriptif (mean, standar deviasi, minimum, maksimum)\n","2. Visualisasi sinyal spektrum daya untuk beberapa sampel dari tiap kelas\n","3. Perbandingan pola spektrum antar subjek\n","4. Analisis variansi fitur antar kelas\n","\n","Tujuan eksplorasi ini adalah untuk:\n","\n","* Mengidentifikasi perbedaan karakteristik antar kelas\n","* Menilai kompleksitas data\n","* Menentukan pendekatan pemodelan yang tepat\n","\n","\n","\n","##### **8. Tantangan Data (Data Challenges)**\n","\n","Beberapa tantangan utama dalam dataset ini antara lain:\n","\n","* Dimensi data yang tinggi dibandingkan jumlah sampel\n","* Potensi redundansi antar fitur spektrum\n","* Variabilitas sinyal antar individu\n","* Risiko *overfitting* jika model terlalu kompleks\n","\n","Tantangan-tantangan ini menjadi pertimbangan penting dalam pemilihan metode dan strategi pemodelan.\n","\n","\n","\n","##### **9. Ringkasan Data Understanding**\n","\n","Dataset SemgHandSubjectCh2 merupakan dataset sinyal sEMG berbasis spektrum daya dengan karakteristik numerik berdimensi tinggi dan target multi-kelas. Dataset ini cocok untuk diterapkan metode klasifikasi berbasis Data Science, dengan tetap memperhatikan tantangan seperti korelasi fitur dan risiko overfitting. Pemahaman yang baik terhadap karakteristik data menjadi dasar penting sebelum memasuki tahap *Data Preparation* dan *Modeling*.\n","\n"],"metadata":{"id":"7nqQTq-eAunx"}},{"cell_type":"markdown","source":["# EDA"],"metadata":{"id":"HZ8GEWKkA8XI"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Rqr4D5pAOID"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import os\n","\n","pd.set_option('display.max_columns', 20)\n","plt.style.use('seaborn-v0_8-whitegrid')\n","\n","train_path = \"dataset/SemgHandSubjectCh2_TRAIN.ts\"\n","test_path  = \"dataset/SemgHandSubjectCh2_TEST.ts\"\n","\n","def load_ts_file(file_path):\n","    encodings = ['utf-8', 'latin-1']\n","    data = []\n","\n","    for enc in encodings:\n","        try:\n","            with open(file_path, 'r', encoding=enc) as file:\n","                is_data = False\n","                for line in file:\n","                    line = line.strip()\n","                    if not line or line.startswith(('#', '%')): continue\n","\n","                    if line.lower().startswith(\"@data\"):\n","                        is_data = True\n","                        continue\n","\n","                    if not is_data: continue\n","                    if ':' in line:\n","                        parts = line.split(':')\n","                        features_str = parts[0]\n","                        label_str = parts[-1]\n","\n","                        values = features_str.split(',')\n","                        values.append(label_str)\n","                    else:\n","                        values = line.split(',')\n","\n","                    data.append(values)\n","            break\n","        except UnicodeDecodeError:\n","            continue\n","\n","    if not data:\n","        raise ValueError(f\"Gagal membaca file {file_path}.\")\n","\n","    df = pd.DataFrame(data)\n","\n","    X = df.iloc[:, :-1].astype(float)\n","    y = df.iloc[:, -1]\n","\n","    return X, y\n","\n","try:\n","    X_train, y_train = load_ts_file(train_path)\n","    X_test, y_test = load_ts_file(test_path)\n","\n","    print(\"1. PEMERIKSAAN STRUKTUR DATA\")\n","    print(f\"Shape (X_train): {X_train.shape}\")\n","    # if X_train.shape[1] == 1500:\n","    #     print(\"âœ… STRUKTUR BENAR: 1500 Fitur terdeteksi.\")\n","    # else:\n","    #     print(f\"âš ï¸ PERINGATAN: Jumlah fitur {X_train.shape[1]} (Harapan: 1500).\")\n","\n","    print(f\"Shape (y_train): {y_train.shape}\")\n","    print(\"-\" * 20)\n","    print(\"Contoh 5 baris pertama data latih (Subset kolom awal):\")\n","    display(X_train.iloc[:, :10].head())\n","\n","    print(\"2. PEMERIKSAAN KUALITAS DATA\")\n","\n","    null_counts = X_train.isnull().sum().sum()\n","    print(f\"Total Missing Values (NaN): {null_counts}\")\n","    unique_labels = y_train.unique()\n","    print(f\"Label Kelas Unik: {sorted(unique_labels)}\")\n","\n","except Exception as e:\n","    print(f\"\\nâŒ ERROR: {e}\")"]},{"cell_type":"code","source":["print(\"3. STATISTIK DESKRIPTIF GLOBAL\")\n","\n","print(\" \")\n","print(f\"Nilai Minimum Global : {X_train.min().min():.4f}\")\n","print(f\"Nilai Maksimum Global: {X_train.max().max():.4f}\")\n","print(f\"Rata-rata Global     : {X_train.mean().mean():.4f}\")\n","print(f\"Std Deviasi Global   : {X_train.std().mean():.4f}\")\n","\n","if X_train.max().max() > 10 or X_train.min().min() < 0:\n","    print(\"ðŸ‘‰ Insight: Rentang nilai bervariasi luas. Normalisasi (MinMax/Standard) SANGAT DISARANKAN nanti.\")\n","else:\n","    print(\"ðŸ‘‰ Insight: Data tampaknya sudah dalam skala kecil.\")\n","\n","print(\" \")\n","print(\"4. VISUALISASI SPEKTRUM PER KELAS (SUBJEK)\")\n","\n","classes = sorted(y_train.unique())\n","colors = sns.color_palette(\"husl\", len(classes))\n","\n","plt.figure(figsize=(15, 10))\n","\n","# Loop untuk setiap kelas (Subjek)\n","for i, label in enumerate(classes):\n","    # Ambil semua sampel milik kelas tersebut\n","    # Kita gunakan boolean indexing\n","    idx = y_train[y_train == label].index\n","    class_data = X_train.loc[idx]\n","\n","    # Hitung Rata-rata Spektrum & Standar Deviasi per titik frekuensi\n","    mean_spectrum = class_data.mean(axis=0)\n","    std_spectrum = class_data.std(axis=0)\n","\n","    # Plotting pada Subplot (biar rapi 5 baris ke bawah)\n","    plt.subplot(len(classes), 1, i+1)\n","\n","    # Plot area standar deviasi (Shading)\n","    x_axis = range(len(mean_spectrum))\n","    plt.fill_between(x_axis,\n","                     mean_spectrum - std_spectrum,\n","                     mean_spectrum + std_spectrum,\n","                     color=colors[i], alpha=0.3, label='Std Dev (Variasi)')\n","\n","    # Plot garis rata-rata\n","    plt.plot(x_axis, mean_spectrum, color=colors[i], linewidth=2, label=f'Rata-rata Subjek {label}')\n","\n","    plt.title(f\"Profil Spektrum - Kelas {label} ({'Wanita' if int(label) <= 3 else 'Pria'})\", fontsize=10, fontweight='bold')\n","    plt.ylabel(\"Amplitudo Daya\")\n","    if i == len(classes)-1:\n","        plt.xlabel(\"Indeks Frekuensi (Fitur 0-1499)\")\n","    plt.legend(loc='upper right')\n","    plt.grid(True, alpha=0.3)\n","\n","plt.tight_layout()\n","plt.show()\n","\n","# --- Plot Overlay (Tumpuk) untuk membandingkan Pria vs Wanita ---\n","plt.figure(figsize=(12, 6))\n","plt.title(\"Perbandingan Rata-rata Spektrum: Subjek 1 (Wanita) vs Subjek 4 (Pria)\")\n","\n","# Ambil rata-rata Kelas 1\n","mean_c1 = X_train.loc[y_train == '1'].mean(axis=0)\n","# Ambil rata-rata Kelas 4\n","mean_c4 = X_train.loc[y_train == '4'].mean(axis=0)\n","\n","plt.plot(mean_c1, label='Kelas 1 (Wanita)', color='red', alpha=0.8)\n","plt.plot(mean_c4, label='Kelas 4 (Pria)', color='blue', alpha=0.8)\n","plt.legend()\n","plt.xlabel(\"Indeks Frekuensi\")\n","plt.ylabel(\"Amplitudo Daya\")\n","plt.grid(True, alpha=0.3)\n","plt.show()"],"metadata":{"id":"WoQa6hM1BEgS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Hasil Temuan**\n","\n","Berdasarkan hasil analisis statistik deskriptif, ditemukan perbedaan yang sangat ekstrem antara nilai minimum sebesar 0,005 dan nilai maksimum sebesar 2238,57, dengan nilai rata-rata (mean) hanya sebesar 16,8. Kondisi ini menunjukkan bahwa sebagian besar data berada pada nilai yang rendah, sementara hanya sedikit data yang memiliki nilai sangat tinggi, sehingga distribusi data bersifat condong (skewed). Karakteristik tersebut mengindikasikan adanya frekuensi dengan energi yang sangat besar dibandingkan frekuensi lainnya. Oleh karena itu, pada tahap preprocessing data diperlukan proses scaling, seperti Min-Max Scaling atau Standard Scaling, untuk menormalkan rentang nilai agar model dapat melakukan pembelajaran secara lebih efektif dan tidak terpengaruh oleh perbedaan skala yang ekstrem.\n"],"metadata":{"id":"uWlY5n1IBG-J"}},{"cell_type":"code","source":["from sklearn.decomposition import PCA\n","from sklearn.manifold import TSNE\n","from sklearn.preprocessing import StandardScaler\n","\n","print(\"5. DISTRIBUSI LABEL KELAS\")\n","\n","plt.figure(figsize=(8, 5))\n","ax = sns.countplot(x=y_train, palette=\"viridis\", hue=y_train, legend=False)\n","plt.title(\"Jumlah Sampel per Subjek (Kelas)\", fontsize=14)\n","plt.xlabel(\"Label Subjek\")\n","plt.ylabel(\"Jumlah Sampel\")\n","plt.grid(axis='y', linestyle='--', alpha=0.7)\n","\n","for p in ax.patches:\n","    ax.annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height()),\n","                ha='center', va='center', xytext=(0, 10), textcoords='offset points')\n","plt.show()\n","\n","print(\"7. HEATMAP KORELASI (SUBSET 50 FITUR PERTAMA)\")\n","print(\"ðŸ‘‰ Mengambil 50 fitur pertama saja agar visualisasi tidak berat/lag.\")\n","\n","subset_features = X_train.iloc[:, :50]\n","corr_matrix = subset_features.corr()\n","\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(corr_matrix, cmap='coolwarm', vmin=-1, vmax=1)\n","plt.title(\"Korelasi Antar 50 Fitur Frekuensi Pertama\")\n","plt.show()\n","\n","from sklearn.decomposition import PCA\n","from sklearn.manifold import TSNE\n","from sklearn.preprocessing import StandardScaler\n","\n","print(\"8. VISUALISASI 2D (PCA & t-SNE)\")\n","\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X_train)\n","\n","pca = PCA(n_components=2)\n","X_pca = pca.fit_transform(X_scaled)\n","print(f\"PCA selesai. Variance Explained: {pca.explained_variance_ratio_.sum()*100:.2f}%\")\n","tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n","X_tsne = tsne.fit_transform(X_scaled)\n","print(\" t-SNE selesai.\")\n","\n","fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n","\n","sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=y_train, palette=\"bright\", ax=axes[0], s=80, alpha=0.8)\n","axes[0].set_title(\"Visualisasi PCA (Linear)\\n(Memisahkan berdasarkan Variansi Global)\", fontsize=12, fontweight='bold')\n","axes[0].set_xlabel(\"PC 1\")\n","axes[0].set_ylabel(\"PC 2\")\n","axes[0].grid(True, alpha=0.3)\n","\n","sns.scatterplot(x=X_tsne[:,0], y=X_tsne[:,1], hue=y_train, palette=\"bright\", ax=axes[1], s=80, alpha=0.8)\n","axes[1].set_title(\"Visualisasi t-SNE (Non-Linear)\\n(Mencari kedekatan pola lokal)\", fontsize=12, fontweight='bold')\n","axes[1].set_xlabel(\"Dimension 1\")\n","axes[1].set_ylabel(\"Dimension 2\")\n","axes[1].grid(True, alpha=0.3)\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"YQt5ZmtPBHo2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.ensemble import IsolationForest\n","from sklearn.decomposition import PCA\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","try:\n","    if 'X_train_final' not in locals():\n","        X_train_check = np.load('processed_data/X_train_final.npy')\n","        y_train_check = np.load('processed_data/y_train_final.npy')\n","    else:\n","        X_train_check = X_train_final\n","        y_train_check = y_train_final\n","except Exception as e:\n","    print(\"Data tidak ditemukan. Pastikan folder processed_data ada.\")\n","\n","iso = IsolationForest(contamination=0.05, random_state=42)\n","y_outliers = iso.fit_predict(X_train_check)\n","\n","outlier_index = np.where(y_outliers == -1)\n","total_outliers = len(outlier_index[0])\n","\n","print(f\"Ditemukan {total_outliers} data yang dicurigai sebagai OUTLIER.\")\n","print(f\"   (Sekitar {total_outliers/len(X_train_check)*100:.2f}% dari total data)\")\n","\n","outlier_labels = y_train_check[outlier_index]\n","unique, counts = np.unique(outlier_labels, return_counts=True)\n","label_names = ['Subjek 1', 'Subjek 2', 'Subjek 3', 'Subjek 4', 'Subjek 5']\n","\n","print(\"\\n Distribusi Outlier per Subjek:\")\n","for u, c in zip(unique, counts):\n","    print(f\"   - {label_names[u]}: {c} sampel terdeteksi aneh.\")\n","\n","pca = PCA(n_components=2)\n","X_pca_outlier = pca.fit_transform(X_train_check)\n","\n","plt.figure(figsize=(10, 6))\n","plt.scatter(X_pca_outlier[y_outliers == 1, 0], X_pca_outlier[y_outliers == 1, 1],\n","            c='blue', label='Normal', alpha=0.5, s=20)\n","plt.scatter(X_pca_outlier[y_outliers == -1, 0], X_pca_outlier[y_outliers == -1, 1],\n","            c='red', label='Outlier', edgecolor='black', s=100, marker='X')\n","\n","plt.title(\"Visualisasi Posisi Outlier (Metode Isolation Forest)\")\n","plt.xlabel(\"PCA 1\")\n","plt.ylabel(\"PCA 2\")\n","plt.legend()\n","plt.grid(True, alpha=0.3)\n","plt.show()\n","\n","if total_outliers > 0:\n","    idx_sample_outlier = outlier_index[0][0] # Ambil outlier pertama\n","    idx_sample_normal = np.where(y_outliers == 1)[0][0] # Ambil normal pertama\n","\n","    plt.figure(figsize=(12, 4))\n","\n","    plt.subplot(1, 2, 1)\n","    plt.plot(X_train_check[idx_sample_normal], color='blue')\n","    plt.title(f\"Contoh Sinyal NORMAL (Index {idx_sample_normal})\")\n","    plt.ylim(-5, 10) # Limit visual agar sebanding (sesuaikan jika perlu)\n","\n","    plt.subplot(1, 2, 2)\n","    plt.plot(X_train_check[idx_sample_outlier], color='red')\n","    plt.title(f\"Contoh Sinyal OUTLIER (Index {idx_sample_outlier})\")\n","    plt.ylim(-5, 10)\n","\n","    plt.tight_layout()\n","    plt.show()"],"metadata":{"id":"wC0O3NVuBNYW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#preprosesing"],"metadata":{"id":"7znDLIp6BQQy"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import os\n","\n","pd.set_option('display.max_columns', 20)\n","plt.style.use('seaborn-v0_8-whitegrid')\n","\n","train_path = \"dataset/SemgHandSubjectCh2_TRAIN.ts\"\n","test_path  = \"dataset/SemgHandSubjectCh2_TEST.ts\"\n","\n","def load_ts_file(file_path):\n","    encodings = ['utf-8', 'latin-1']\n","    data = []\n","\n","    for enc in encodings:\n","        try:\n","            with open(file_path, 'r', encoding=enc) as file:\n","                is_data = False\n","                for line in file:\n","                    line = line.strip()\n","                    if not line or line.startswith(('#', '%')): continue\n","\n","                    if line.lower().startswith(\"@data\"):\n","                        is_data = True\n","                        continue\n","\n","                    if not is_data: continue\n","\n","                    if ':' in line:\n","                        parts = line.split(':')\n","                        features_str = parts[0]\n","                        label_str = parts[-1]\n","\n","                        values = features_str.split(',')\n","                        values.append(label_str)\n","                    else:\n","                        # Jika tidak ada titik dua, asumsi dipisah koma semua\n","                        values = line.split(',')\n","\n","                    data.append(values)\n","            break\n","        except UnicodeDecodeError:\n","            continue\n","\n","    if not data:\n","        raise ValueError(f\"Gagal membaca file {file_path}.\")\n","\n","    # Konversi ke DataFrame\n","    df = pd.DataFrame(data)\n","\n","    X = df.iloc[:, :-1].astype(float)\n","    y = df.iloc[:, -1]\n","\n","    return X, y\n","\n","X_train, y_train = load_ts_file(train_path)\n","X_test, y_test = load_ts_file(test_path)"],"metadata":{"id":"l4dsGECZBRmG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler, LabelEncoder\n","print(\"   TAHAP DATA PREPARATION   \")\n","\n","le = LabelEncoder()\n","\n","y_train_encoded = le.fit_transform(y_train)\n","y_test_encoded = le.transform(y_test)\n","\n","print(\"\\n\")\n","print(\" Label Encoding Selesai.\")\n","print(f\"   Mapping Kelas: {dict(zip(le.classes_, le.transform(le.classes_)))}\")\n","print(f\"   Contoh Label Lama : {y_train.iloc[:5].values}\")\n","print(f\"   Contoh Label Baru : {y_train_encoded[:5]}\")\n","\n","scaler = StandardScaler()\n","\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled  = scaler.transform(X_test)\n","\n","print(\"\\n Feature Scaling (StandardScaler) Selesai.\")\n","print(f\"   Mean sebelum scaling : {X_train.values.mean():.4f}\")\n","print(f\"   Mean setelah scaling : {X_train_scaled.mean():.4f}\")\n","print(f\"   Std  setelah scaling : {X_train_scaled.std():.4f} \")\n","\n","X_train_final = X_train_scaled\n","X_test_final  = X_test_scaled\n","y_train_final = y_train_encoded\n","y_test_final  = y_test_encoded\n","\n","print(\"\\n DATA SIAP UNTUK PEMODELAN (MODELING)!\")\n","print(f\"   Dimensi X_train_final: {X_train_final.shape}\")\n","print(f\"   Dimensi y_train_final: {y_train_final.shape}\")"],"metadata":{"id":"ZS1v8rZhBTtQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_before = X_train.iloc[:5, :10]\n","X_after  = pd.DataFrame(\n","    X_train_final[:5, :10],\n","    columns=X_train.columns[:10],\n","    index=X_train.index[:5]\n",")\n","\n","print(\"\\n Data Sebelum Scaling:\")\n","display(X_before)\n","\n","print(\"\\n Data Sesudah Scaling (StandardScaler):\")\n","display(X_after)"],"metadata":{"id":"f9eu1Q_1BVeA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["comparison_stats = pd.DataFrame({\n","    \"Mean Sebelum\": X_train.iloc[:, :10].mean(),\n","    \"Std Sebelum\": X_train.iloc[:, :10].std(),\n","    \"Mean Sesudah\": X_train_final[:, :10].mean(axis=0),\n","    \"Std Sesudah\": X_train_final[:, :10].std(axis=0)\n","})\n","\n","display(comparison_stats)"],"metadata":{"id":"UAEz41TEBX5k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import os\n","import joblib\n","\n","\n","print(\"   MENYIMPAN DATA (SAVING)   \")\n","\n","save_dir = \"processed_data\"\n","os.makedirs(save_dir, exist_ok=True)\n","\n","np.save(os.path.join(save_dir, 'X_train_final.npy'), X_train_final)\n","np.save(os.path.join(save_dir, 'X_test_final.npy'), X_test_final)\n","np.save(os.path.join(save_dir, 'y_train_final.npy'), y_train_final)\n","np.save(os.path.join(save_dir, 'y_test_final.npy'), y_test_final)\n","\n","print(f\" Data berhasil disimpan di folder: '{save_dir}/'\")\n","print(f\"   - {save_dir}/X_train_final.npy\")\n","print(f\"   - {save_dir}/X_test_final.npy\")\n","print(f\"   - {save_dir}/y_train_final.npy\")\n","print(f\"   - {save_dir}/y_test_final.npy\")\n","\n","os.makedirs(\"models\", exist_ok=True)\n","joblib.dump(scaler, 'models/scaler.pkl')\n","\n","print(\"Scaler berhasil disimpan di: models/scaler.pkl\")"],"metadata":{"id":"seJbfyUmBZlJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#modeling"],"metadata":{"id":"BeGWdxB5BcJ_"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.linear_model import RidgeClassifierCV\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","import seaborn as sns\n","import time\n","\n","try:\n","    from sktime.transformations.panel.rocket import MiniRocket\n","    print(\"Library 'sktime' terdeteksi.\")\n","except ImportError:\n","    print(\"Library 'sktime' belum terinstall!\")\n","    print(\"Silakan jalankan di terminal: pip install sktime\")\n","    # Stop eksekusi jika library tidak ada\n","    raise\n","\n","# --- 1. DATA RESHAPING (PENTING!) ---\n","# sktime MiniRocket butuh input 3D: (Jumlah Sampel, Jumlah Channel, Panjang Sinyal)\n","# Data kita saat ini 2D: (450, 1500) -> Kita ubah jadi (450, 1, 1500)\n","\n","print(\"   MINIROCKET + RIDGE CLASSIFIER   \")\n","\n","X_train_rocket = X_train_final.reshape(X_train_final.shape[0], 1, X_train_final.shape[1])\n","X_test_rocket  = X_test_final.reshape(X_test_final.shape[0], 1, X_test_final.shape[1])\n","\n","print(f\"Dimensi Input MiniRocket (Train): {X_train_rocket.shape}\")\n","print(f\"Dimensi Input MiniRocket (Test) : {X_test_rocket.shape}\")\n","\n","# --- 2. TRANSFORMASI MINIROCKET ---\n","print(\"\\n Sedang melakukan Transformasi MiniRocket (Ekstraksi Fitur)...\")\n","start_time = time.time()\n","\n","minirocket = MiniRocket()\n","X_train_transform = minirocket.fit_transform(X_train_rocket)\n","X_test_transform = minirocket.transform(X_test_rocket)\n","\n","end_time = time.time()\n","print(f\"Transformasi Selesai dalam {end_time - start_time:.2f} detik.\")\n","print(f\"   Shape Baru Train: {X_train_transform.shape} (Perhatikan jumlah fiturnya meledak jadi ~10.000!)\")\n","print(\"\\n Sedang melatih Ridge ClassifierCV (Linear Model)...\")\n","\n","classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10))\n","classifier.fit(X_train_transform, y_train_final)\n","\n","# --- 4. EVALUASI ---\n","y_pred_rocket = classifier.predict(X_test_transform)\n","acc_rocket = accuracy_score(y_test_final, y_pred_rocket)\n","\n","print(f\"\\n HASIL AKHIR MINIROCKET:\")\n","print(f\"   Akurasi: {acc_rocket*100:.2f}%\")\n","\n","# --- 5. VISUALISASI HASIL ---\n","target_names_manual = ['Subjek 1', 'Subjek 2', 'Subjek 3', 'Subjek 4', 'Subjek 5']\n","\n","print(\"-\" * 30)\n","if acc_rocket > 0.8:\n","    print(classification_report(y_test_final, y_pred_rocket, target_names=target_names_manual))\n","\n","plt.figure(figsize=(8, 6))\n","cm = confusion_matrix(y_test_final, y_pred_rocket)\n","\n","# Plot Heatmap\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Greens',\n","            xticklabels=target_names_manual, yticklabels=target_names_manual)\n","plt.xlabel(\"Prediksi Model\")\n","plt.ylabel(\"Label Sebenarnya (Aktual)\")\n","plt.title(f\"Confusion Matrix - MiniRocket (Acc: {acc_rocket*100:.2f}%)\")\n","plt.show()"],"metadata":{"id":"wD2kTr14BdKm"},"execution_count":null,"outputs":[]}]}